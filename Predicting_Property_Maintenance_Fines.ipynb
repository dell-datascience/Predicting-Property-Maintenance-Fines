{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Understanding and Predicting Property Maintenance Fines\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#training\">Model selection training and evalution</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "[Blight violations](http://www.detroitmi.gov/How-Do-I/Report/Blight-Complaint-FAQs) are issued by the city to individuals who allow their properties to remain in a deteriorated condition. Every year, the city of Detroit issues millions of dollars in fines to residents and every year, many of these fines remain unpaid. Enforcing unpaid blight fines is a costly and tedious process, so the city wants to know: how can we increase blight ticket compliance?\n",
    "\n",
    "This project is focused on understanding when and why a resident might fail to comply with a blight ticket by training a model to predict blight ticket compliance in Detroit using `readonly/train.csv`. Using this model, return the probability that each corresponding ticket from `readonly/test.csv` will be paid.\n",
    "\n",
    "\n",
    "### Dataset Description \n",
    "\n",
    "This project is based on a data challenge from the Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/))who partnered with the City of Detroit to help solve one of the most pressing blight problem facing Detroit. \n",
    "\n",
    "Each row in these two files corresponds to a single blight ticket, and includes information about when, why, and to whom each ticket was issued. The target variable is compliance, which is True if the ticket was paid early, on time, or within one month of the hearing date, False if the ticket was paid after the hearing date or not at all, and Null if the violator was found not responsible. Compliance, as well as a handful of other variables that will not be available at test-time, are only included in train.csv.\n",
    "\n",
    "**Data fields**\n",
    "train.csv & test.csv\n",
    "\n",
    "    ticket_id - unique identifier for tickets\n",
    "    agency_name - Agency that issued the ticket\n",
    "    inspector_name - Name of inspector that issued the ticket\n",
    "    violator_name - Name of the person/organization that the ticket was issued to\n",
    "    violation_street_number, violation_street_name, violation_zip_code - Address where the violation occurred\n",
    "    mailing_address_str_number, mailing_address_str_name, city, state, zip_code, non_us_str_code, country - Mailing address of the violator\n",
    "    ticket_issued_date - Date and time the ticket was issued\n",
    "    hearing_date - Date and time the violator's hearing was scheduled\n",
    "    violation_code, violation_description - Type of violation\n",
    "    disposition - Judgment and judgement type\n",
    "    fine_amount - Violation fine amount, excluding fees\n",
    "    admin_fee - $20 fee assigned to responsible judgments\n",
    "state_fee - $10 fee assigned to responsible judgments\n",
    "    late_fee - 10% fee assigned to responsible judgments\n",
    "    discount_amount - discount applied, if any\n",
    "    clean_up_cost - DPW clean-up or graffiti removal cost\n",
    "    judgment_amount - Sum of all fines and fees\n",
    "    grafitti_status - Flag for graffiti violations\n",
    "    \n",
    "train.csv only\n",
    "\n",
    "    payment_amount - Amount paid, if any\n",
    "    payment_date - Date payment was made, if it was received\n",
    "    payment_status - Current payment status as of Feb 1 2017\n",
    "    balance_due - Fines and fees still owed\n",
    "    collection_status - Flag for payments in collections\n",
    "    compliance [target variable for prediction] \n",
    "     Null = Not responsible\n",
    "     0 = Responsible, non-compliant\n",
    "     1 = Responsible, compliant\n",
    "    compliance_detail - More information on why each ticket was marked compliant or non-compliant\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "The predictions give the probability that the corresponding blight ticket will be paid on time.\n",
    "The evaluation metric for this project is the Area Under the ROC Curve (AUC). Model gives AUC score of above 0.75\n",
    "\n",
    "Example:\n",
    "\n",
    "    ticket_id\n",
    "       284932    0.531842\n",
    "       285362    0.401958\n",
    "       285361    0.105928\n",
    "       285338    0.018572\n",
    "                 ...\n",
    "       376499    0.208567\n",
    "       376500    0.818759\n",
    "       369851    0.018528\n",
    "       Name: compliance, dtype: float32\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling'></a>\n",
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "    \n",
    "# Load the data files\n",
    "train = pd.read_csv('train.csv',encoding='ISO-8859-1',low_memory=False,parse_dates=['ticket_issued_date', 'hearing_date','payment_date'])\n",
    "test  = pd.read_csv('test.csv',encoding='ISO-8859-1',low_memory=False, parse_dates=['ticket_issued_date', 'hearing_date'])\n",
    "address = pd.read_csv('addresses.csv',encoding='ISO-8859-1',low_memory=False)\n",
    "coord   = pd.read_csv('latlons.csv',encoding='ISO-8859-1',low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually examine tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>inspector_name</th>\n",
       "      <th>violator_name</th>\n",
       "      <th>violation_street_number</th>\n",
       "      <th>violation_street_name</th>\n",
       "      <th>violation_zip_code</th>\n",
       "      <th>mailing_address_str_number</th>\n",
       "      <th>mailing_address_str_name</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>clean_up_cost</th>\n",
       "      <th>judgment_amount</th>\n",
       "      <th>payment_amount</th>\n",
       "      <th>balance_due</th>\n",
       "      <th>payment_date</th>\n",
       "      <th>payment_status</th>\n",
       "      <th>collection_status</th>\n",
       "      <th>grafitti_status</th>\n",
       "      <th>compliance_detail</th>\n",
       "      <th>compliance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126148</th>\n",
       "      <td>153633</td>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Samaan, Neil J</td>\n",
       "      <td>HUTCHINS, OTTO</td>\n",
       "      <td>19304.0</td>\n",
       "      <td>HOOVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1414.0</td>\n",
       "      <td>PO BOX</td>\n",
       "      <td>WARREN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NO PAYMENT APPLIED</td>\n",
       "      <td>IN COLLECTION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-compliant by no payment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235889</th>\n",
       "      <td>270124</td>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Samaan, Neil J</td>\n",
       "      <td>BISZCZANIK, MAREK</td>\n",
       "      <td>7425.0</td>\n",
       "      <td>DAVISON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6876.0</td>\n",
       "      <td>MEADOWLAKE RD</td>\n",
       "      <td>BMFD TWP</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NO PAYMENT APPLIED</td>\n",
       "      <td>IN COLLECTION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-compliant by no payment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90156</th>\n",
       "      <td>115317</td>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Samaan, Neil J</td>\n",
       "      <td>MISSIONARY, EMMANUEL</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>OAKMAN BLVD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21143.0</td>\n",
       "      <td>PO BOX</td>\n",
       "      <td>DETROIT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NO PAYMENT APPLIED</td>\n",
       "      <td>IN COLLECTION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-compliant by no payment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ticket_id                                     agency_name  \\\n",
       "126148     153633  Buildings, Safety Engineering & Env Department   \n",
       "235889     270124  Buildings, Safety Engineering & Env Department   \n",
       "90156      115317  Buildings, Safety Engineering & Env Department   \n",
       "\n",
       "        inspector_name         violator_name  violation_street_number  \\\n",
       "126148  Samaan, Neil J        HUTCHINS, OTTO                  19304.0   \n",
       "235889  Samaan, Neil J     BISZCZANIK, MAREK                   7425.0   \n",
       "90156   Samaan, Neil J  MISSIONARY, EMMANUEL                   1271.0   \n",
       "\n",
       "       violation_street_name  violation_zip_code  mailing_address_str_number  \\\n",
       "126148                HOOVER                 NaN                      1414.0   \n",
       "235889               DAVISON                 NaN                      6876.0   \n",
       "90156            OAKMAN BLVD                 NaN                     21143.0   \n",
       "\n",
       "       mailing_address_str_name      city  ... clean_up_cost judgment_amount  \\\n",
       "126148                   PO BOX    WARREN  ...           0.0           305.0   \n",
       "235889            MEADOWLAKE RD  BMFD TWP  ...           0.0           305.0   \n",
       "90156                    PO BOX   DETROIT  ...           0.0           305.0   \n",
       "\n",
       "       payment_amount balance_due payment_date      payment_status  \\\n",
       "126148            0.0       305.0          NaT  NO PAYMENT APPLIED   \n",
       "235889            0.0       305.0          NaT  NO PAYMENT APPLIED   \n",
       "90156             0.0       305.0          NaT  NO PAYMENT APPLIED   \n",
       "\n",
       "       collection_status grafitti_status            compliance_detail  \\\n",
       "126148     IN COLLECTION             NaN  non-compliant by no payment   \n",
       "235889     IN COLLECTION             NaN  non-compliant by no payment   \n",
       "90156      IN COLLECTION             NaN  non-compliant by no payment   \n",
       "\n",
       "        compliance  \n",
       "126148         0.0  \n",
       "235889         0.0  \n",
       "90156          0.0  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250306, 34)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152790</th>\n",
       "      <td>182446</td>\n",
       "      <td>1975 webb, Detroit MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85121</th>\n",
       "      <td>110178</td>\n",
       "      <td>5418 iroquois, Detroit MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163791</th>\n",
       "      <td>193718</td>\n",
       "      <td>2082 vinewood, Detroit MI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ticket_id                    address\n",
       "152790     182446      1975 webb, Detroit MI\n",
       "85121      110178  5418 iroquois, Detroit MI\n",
       "163791     193718  2082 vinewood, Detroit MI"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30389</th>\n",
       "      <td>4867 avery, Detroit MI</td>\n",
       "      <td>42.351081</td>\n",
       "      <td>-83.081252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115680</th>\n",
       "      <td>1155 lenore, Detroit MI</td>\n",
       "      <td>42.421118</td>\n",
       "      <td>-83.281344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106383</th>\n",
       "      <td>1524 military, Detroit MI</td>\n",
       "      <td>42.313517</td>\n",
       "      <td>-83.104955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          address        lat        lon\n",
       "30389      4867 avery, Detroit MI  42.351081 -83.081252\n",
       "115680    1155 lenore, Detroit MI  42.421118 -83.281344\n",
       "106383  1524 military, Detroit MI  42.313517 -83.104955"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250306 entries, 0 to 250305\n",
      "Data columns (total 34 columns):\n",
      " #   Column                      Non-Null Count   Dtype         \n",
      "---  ------                      --------------   -----         \n",
      " 0   ticket_id                   250306 non-null  int64         \n",
      " 1   agency_name                 250306 non-null  object        \n",
      " 2   inspector_name              250306 non-null  object        \n",
      " 3   violator_name               250272 non-null  object        \n",
      " 4   violation_street_number     250306 non-null  float64       \n",
      " 5   violation_street_name       250306 non-null  object        \n",
      " 6   violation_zip_code          0 non-null       float64       \n",
      " 7   mailing_address_str_number  246704 non-null  float64       \n",
      " 8   mailing_address_str_name    250302 non-null  object        \n",
      " 9   city                        250306 non-null  object        \n",
      " 10  state                       250213 non-null  object        \n",
      " 11  zip_code                    250305 non-null  object        \n",
      " 12  non_us_str_code             3 non-null       object        \n",
      " 13  country                     250306 non-null  object        \n",
      " 14  ticket_issued_date          250306 non-null  datetime64[ns]\n",
      " 15  hearing_date                237815 non-null  datetime64[ns]\n",
      " 16  violation_code              250306 non-null  object        \n",
      " 17  violation_description       250306 non-null  object        \n",
      " 18  disposition                 250306 non-null  object        \n",
      " 19  fine_amount                 250305 non-null  float64       \n",
      " 20  admin_fee                   250306 non-null  float64       \n",
      " 21  state_fee                   250306 non-null  float64       \n",
      " 22  late_fee                    250306 non-null  float64       \n",
      " 23  discount_amount             250306 non-null  float64       \n",
      " 24  clean_up_cost               250306 non-null  float64       \n",
      " 25  judgment_amount             250306 non-null  float64       \n",
      " 26  payment_amount              250306 non-null  float64       \n",
      " 27  balance_due                 250306 non-null  float64       \n",
      " 28  payment_date                41113 non-null   datetime64[ns]\n",
      " 29  payment_status              250306 non-null  object        \n",
      " 30  collection_status           36897 non-null   object        \n",
      " 31  grafitti_status             1 non-null       object        \n",
      " 32  compliance_detail           250306 non-null  object        \n",
      " 33  compliance                  159880 non-null  float64       \n",
      "dtypes: datetime64[ns](3), float64(13), int64(1), object(17)\n",
      "memory usage: 64.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id                          0\n",
       "agency_name                        0\n",
       "inspector_name                     0\n",
       "violator_name                     34\n",
       "violation_street_number            0\n",
       "violation_street_name              0\n",
       "violation_zip_code            250306\n",
       "mailing_address_str_number      3602\n",
       "mailing_address_str_name           4\n",
       "city                               0\n",
       "state                             93\n",
       "zip_code                           1\n",
       "non_us_str_code               250303\n",
       "country                            0\n",
       "ticket_issued_date                 0\n",
       "hearing_date                   12491\n",
       "violation_code                     0\n",
       "violation_description              0\n",
       "disposition                        0\n",
       "fine_amount                        1\n",
       "admin_fee                          0\n",
       "state_fee                          0\n",
       "late_fee                           0\n",
       "discount_amount                    0\n",
       "clean_up_cost                      0\n",
       "judgment_amount                    0\n",
       "payment_amount                     0\n",
       "balance_due                        0\n",
       "payment_date                  209193\n",
       "payment_status                     0\n",
       "collection_status             213409\n",
       "grafitti_status               250305\n",
       "compliance_detail                  0\n",
       "compliance                     90426\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Strategize wrangling path by defining cleaning process on `train` table.\n",
    "\n",
    "#### Quality\n",
    "\n",
    "- Missing demographic information (payment_date, collection_status, grafitti_status, compliance, violator_name, violation_zip_code, mailing_address_str_number, mailing_address_str_name, state, zip_code, non_us_str_code, hearing_date contact columns) ***(can't clean yet)***\n",
    "\n",
    "#### Tidiness\n",
    "- Columns with all entries being zero should be removed.\n",
    "- Columns with the same values should be removed as they are uncorrelated with target variable.\n",
    "- Columns with total unique values less than 10% of entries (<250) should be converted into categorical data to reduce memory usage to reduce memory usage.\n",
    "- Remove columns with missing value % of more than 50%.\n",
    "- Join the address table to train and test tables to expand features.\n",
    "- With address joined, now remove features that can be replaced with address, such as :\n",
    "\n",
    "`\n",
    "['violator_name','violation_street_number',\n",
    "'violation_street_name','mailing_address_str_number',\n",
    "'mailing_address_str_name','state', 'zip_code', 'country','address','city'] `\n",
    "\n",
    "- Reduce the features even further, by suming the amount payables into one.\n",
    "- drop missing values of ['lat','lon','total_amt_pay'] from the train dataset \n",
    "- Replace ticket issue data and the hearing date with the time gap between them.\n",
    "- Now remove not too important featured and make strinig features from string categories \n",
    "\n",
    "`\n",
    "['inspector_name', 'violation_code','violation_description',\n",
    " 'payment_amount', 'balance_due','payment_status',\n",
    " 'compliance_detail']\n",
    " `\n",
    " \n",
    " - taking only non-NaN values for training\n",
    " - trime the train data to have only the columns available in the test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we remove columns and rows with all entries being EMPTY\n",
    "train.dropna(how='all',axis=1, inplace=True)\n",
    "train.dropna(how='all',axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with the same values they are independent/non-correlated to/from target values\n",
    "independent = []\n",
    "for i in range(len(train.columns)):\n",
    "    if len(train[train.columns[i]].unique())==1:\n",
    "        independent.append(train.columns[i])\n",
    "\n",
    "train.drop(independent,axis=1,inplace=True)\n",
    "test.drop(independent,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that there are a lot of columns with total unique values less than 250.Thus we can convert them into categorical data to reduce memory usage\n",
    "# to reduce memory usage we convert columns with < than 250 entries to categorical data\n",
    "\n",
    "for i in range(len(train.columns)):\n",
    "    if len(train[train.columns[i]].unique())<250:\n",
    "        train[train.columns[i]] = train[train.columns[i]].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now lets see the missing number ratio in the data set\n",
    "total_null = train.isnull().sum().sort_values(ascending=False)\n",
    "per        = train.isnull().count().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now i remove columns with missing value percentage of more than 50%\n",
    "\n",
    "high_mssing_data = pd.concat([total_null,total_null/per], keys=['Total_nulls','percentage_nulls'],axis=1)\n",
    "high_missing_values = high_mssing_data[high_mssing_data['percentage_nulls']>0.5].index\n",
    "train.drop(high_missing_values,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we join the address to train and test data\n",
    "address = address.merge(coord,how='inner',left_on='address',right_on='address')\n",
    "train = train.merge(address,how='left',left_on='ticket_id',right_on='ticket_id')\\\n",
    "                .set_index('ticket_id')\n",
    "test  = test.merge(address,how='left',left_on='ticket_id',right_on='ticket_id')\\\n",
    "                .set_index('ticket_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we reduce the features that can be replaced by the lat and lon\n",
    "latlon_replaced = ['violator_name',\n",
    "       'violation_street_number', 'violation_street_name',\n",
    "       'mailing_address_str_number', 'mailing_address_str_name',\n",
    "       'state', 'zip_code', 'country','address','city']\n",
    "train.drop(latlon_replaced, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we reduce the features even further, by suming the amount payables into one\n",
    "train['total_amt_pay'] = train[['fine_amount','admin_fee','state_fee','late_fee']].sum(axis=1).subtract(train['discount_amount'].astype(np.float64))\n",
    "test['total_amt_pay']  = test[['fine_amount','admin_fee','state_fee','late_fee']].sum(axis=1).subtract(test['discount_amount'].astype(np.float64))\n",
    "drop_payments = ['fine_amount','admin_fee','state_fee','late_fee','discount_amount']\n",
    "train.drop(drop_payments,axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values of ['lat','lon','total_amt_pay'] from the train dataset but since its not allowed in the test set,we replace it with the mean\n",
    "train.dropna(subset = ['lat','lon','total_amt_pay'],inplace=True)\n",
    "test['lat'].fillna(test.lat.mean(),inplace=True)\n",
    "test['lon'].fillna(test.lon.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we find the time gap between the ticket issue data and the hearing date\n",
    "train['time_delta'] = (train['hearing_date'] - train['ticket_issued_date']).dt.days\n",
    "test['time_delta']  = (test['hearing_date'] - test['ticket_issued_date']).dt.days\n",
    "drop_timedelta = ['hearing_date','ticket_issued_date'] \n",
    "train.drop(drop_timedelta,axis=1, inplace=True)\n",
    "test.drop(drop_timedelta,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace the missing values in the time delta column with the mode\n",
    "train['time_delta'].fillna(73, inplace=True)\n",
    "test['time_delta'].fillna(73,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now remove not too important featured and make strinig features from string categories 'disposition','agancy_name'\n",
    "further_drop = ['inspector_name', 'violation_code','violation_description',\n",
    "                'payment_amount', 'balance_due','payment_status',\n",
    "                'compliance_detail']\n",
    "\n",
    "train.drop(further_drop,axis=1, inplace=True)\n",
    "string_features = ['disposition','agency_name'] \n",
    "train = pd.get_dummies(train,columns = string_features,drop_first=True)\n",
    "test = pd.get_dummies(test,columns = string_features,drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking only non-NaN values for training\n",
    "train = train[( (train['compliance']==0) | (train['compliance']==1) )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trime the train data to have only the columns available in the test data\n",
    "y = train['compliance']\n",
    "X = train.drop('compliance',axis=1)\n",
    "\n",
    "train_feature_set = set(X)\n",
    "for feature in set(X):\n",
    "    if feature not in test:\n",
    "        train_feature_set.remove(feature)\n",
    "\n",
    "train_features = list(train_feature_set)\n",
    "X_train = X[train_features]\n",
    "test    = test[train_features]\n",
    "\n",
    "# X_train, y, test, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='training'></a>\n",
    "## Model selection, training and evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split                                    ,GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\\\n",
    "                             ,RandomForestRegressor\\\n",
    "                             ,GradientBoostingClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159878, 11), (159878,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide train test split for model selection\n",
    "x_train,x_test,y_train,y_test= train_test_split(X_train,y,test_size=0.4,random_state=40)\n",
    "X_train.shape,y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.01413583755493164 \n",
      "ROC_score : 0.5\n"
     ]
    }
   ],
   "source": [
    "# implement dummy classifier as base model, using most frequent data as prediction\n",
    "start = time.time()\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent').fit(x_train,y_train)\n",
    "y_pred = dummy_clf.predict(x_test)\n",
    "print('Runtime: {} \\nROC_score : {}'.format(time.time()- start,\\\n",
    "                                      roc_auc_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter is: {'n_neighbors': 9}\n",
      "Best ROC_score is: 0.7494481978035308\n",
      "Runtime: 29.89334988594055\n"
     ]
    }
   ],
   "source": [
    "# implementing KNN classifier\n",
    "start = time.time()\n",
    "KN_clf = KNeighborsRegressor()\n",
    "param_values = {'n_neighbors':[1,3,5,7,9]}\n",
    "grid_clf = GridSearchCV(KN_clf, param_grid=param_values,scoring='roc_auc').fit(x_train,y_train)\n",
    "print('Best parameter is: {}\\nBest ROC_score is: {}'.format(grid_clf.best_params_,grid_clf.best_score_))\n",
    "print('Runtime: {}'.format(time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/air/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.03558e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
      "/Users/air/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=9.24063e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter is {'alpha': 0}\n",
      "Best ROC_score is 0.7723439974165995\n",
      "Runtime: 3.734174966812134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/air/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.47116e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "# implenting Ridge classifier\n",
    "start = time.time()\n",
    "R_clf = RidgeClassifier()\n",
    "R_clf.get_params().keys()\n",
    "param_values = {'alpha':[0, 1, 10, 20, 50, 100, 1000]}\n",
    "grid_clf = GridSearchCV(R_clf, param_grid=param_values,scoring='roc_auc').fit(x_train,y_train)\n",
    "print('Best parameter is {}\\nBest ROC_score is {}'.format(grid_clf.best_params_,grid_clf.best_score_))\n",
    "print('Runtime: {}'.format(time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter is {'max_depth': 15}\n",
      "Best ROC_score is 0.8197865894627888\n",
      "Runtime: 1321.5681660175323\n"
     ]
    }
   ],
   "source": [
    "# implenting random forest regressor\n",
    "start = time.time()\n",
    "RF_clf = RandomForestRegressor()\n",
    "param_values = {'max_depth':[1,3,5,7,9,11,13,15,17,18,21]}\n",
    "# X_train = MinMaxScaler().fit_transform(X_train)\n",
    "# # testt = MinMaxScaler().fit_transform(test)\n",
    "grid_clf = GridSearchCV(RF_clf, param_grid=param_values,scoring='roc_auc').fit(x_train,y_train)\n",
    "print('Best parameter is {}\\nBest ROC_score is {}'.format(grid_clf.best_params_,grid_clf.best_score_))\n",
    "print('Runtime: {}'.format(time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter is {'gamma': 100}\n",
      "Best ROC_score is 0.6964877516589298\n",
      "Runtime: 4802.026435136795\n"
     ]
    }
   ],
   "source": [
    "# implementing support vector machine classifier\n",
    "start = time.time()\n",
    "SV = SVC(kernel = 'rbf',C = 0.01)\n",
    "param_value = {'gamma': [0.01,0.1,1,10,100,]}\n",
    "grid_clf = GridSearchCV(SV,param_grid= param_value ,scoring = 'roc_auc').fit(x_train,y_train)\n",
    "print('Best parameter is {}\\nBest ROC_score is {}'.format(grid_clf.best_params_,grid_clf.best_score_))\n",
    "print('Runtime: {}'.format(time.time()-start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest regressor is selected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def blight_model(X_train, y, test):\n",
    "    #import necessary models to train the data\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "   \n",
    "    RF_clf = RandomForestRegressor(max_depth=6).fit(X_train,y)\n",
    "    y_pred = RF_clf.predict(test)\n",
    "    test['compliance'] = y_pred\n",
    "    return test.compliance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id\n",
       "284932    0.063016\n",
       "285362    0.013487\n",
       "285361    0.068180\n",
       "285338    0.083102\n",
       "285346    0.087070\n",
       "            ...   \n",
       "376496    0.013312\n",
       "376497    0.013312\n",
       "376499    0.070316\n",
       "376500    0.070316\n",
       "369851    0.399647\n",
       "Name: compliance, Length: 61001, dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blight_model(X_train, y, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "nNS8l",
   "launcher_item_id": "yWWk7",
   "part_id": "w8BSS"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
